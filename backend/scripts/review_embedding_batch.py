#!/usr/bin/env python3
"""
ë¦¬ë·° ë°ì´í„° ë°°ì¹˜ ì„ë² ë”© ìƒì„± ìŠ¤í¬ë¦½íŠ¸

Vertex AI text-multilingual-embedding-002 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬
ë¦¬ë·° í…ìŠ¤íŠ¸ì˜ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  OpenSearchì— ì €ì¥í•©ë‹ˆë‹¤.
"""

import os
import sys
import json
import time
import asyncio
import argparse
from typing import List, Dict, Any, Optional
from datetime import datetime

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°±ì—”ë“œ ì•± ê²½ë¡œ ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_dir = os.path.dirname(current_dir)
sys.path.append(backend_dir)

import mysql.connector
from loguru import logger
from google.cloud import aiplatform
from google.oauth2 import service_account
from opensearchpy import OpenSearch, RequestsHttpConnection


class ReviewEmbeddingBatch:
    """ë¦¬ë·° ì„ë² ë”© ë°°ì¹˜ ìƒì„±ê¸°"""
    
    def __init__(self):
        # MySQL ì„¤ì •
        self.mysql_config = {
            'host': os.getenv('MYSQL_HOST', 'localhost'),
            'port': int(os.getenv('MYSQL_PORT', 3306)),
            'user': os.getenv('MYSQL_USER', 'root'),
            'password': os.getenv('MYSQL_PASSWORD', 'password'),
            'database': os.getenv('MYSQL_DATABASE', 'commerce_db'),
            'charset': 'utf8mb4'
        }
        
        # OpenSearch ì„¤ì •
        self.opensearch_config = {
            'hosts': [{'host': os.getenv('OPENSEARCH_HOST', 'localhost'), 'port': int(os.getenv('OPENSEARCH_PORT', 9200))}],
            'http_auth': (os.getenv('OPENSEARCH_USERNAME', 'admin'), os.getenv('OPENSEARCH_PASSWORD', 'admin')),
            'use_ssl': os.getenv('OPENSEARCH_USE_SSL', 'false').lower() == 'true',
            'verify_certs': os.getenv('OPENSEARCH_VERIFY_CERTS', 'false').lower() == 'true',
            'ssl_assert_hostname': False,
            'ssl_show_warn': False,
            'connection_class': RequestsHttpConnection
        }
        
        # Vertex AI ì„¤ì •
        self.project_id = os.getenv("GOOGLE_CLOUD_PROJECT_ID")
        self.location = os.getenv("GOOGLE_CLOUD_LOCATION", "us-central1")
        self.model_name = os.getenv("VERTEX_EMBEDDING_MODEL", "text-multilingual-embedding-002")
        
        # ë°°ì¹˜ ì„¤ì •
        self.batch_size = 50  # MySQL ë°°ì¹˜ ì‚¬ì´ì¦ˆ
        self.embedding_batch_size = 5  # Vertex AI API ë°°ì¹˜ ì‚¬ì´ì¦ˆ
        self.max_retries = 3
        self.retry_delay = 2.0
        
        # ì§„í–‰ìƒí™© ì €ì¥
        self.checkpoint_file = "review_embedding_checkpoint.json"
        self.stats = {
            'total_reviews': 0,
            'processed_reviews': 0,
            'successful_embeddings': 0,
            'failed_embeddings': 0,
            'start_time': None,
            'last_processed_id': 0
        }
        
        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.mysql_conn = None
        self.opensearch_client = None
        self.vertex_client = None
        
        # ë¡œê¹… ì„¤ì •
        logger.add("review_embedding_batch.log", rotation="10 MB", level="INFO")
    
    def initialize_clients(self):
        """ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            # MySQL ì—°ê²°
            self.mysql_conn = mysql.connector.connect(**self.mysql_config)
            logger.info("MySQL ì—°ê²° ì„±ê³µ")
            
            # OpenSearch ì—°ê²°
            self.opensearch_client = OpenSearch(**self.opensearch_config)
            logger.info("OpenSearch ì—°ê²° ì„±ê³µ")
            
            # Vertex AI ì´ˆê¸°í™”
            credentials_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
            if credentials_path and os.path.exists(credentials_path):
                credentials = service_account.Credentials.from_service_account_file(credentials_path)
                aiplatform.init(
                    project=self.project_id,
                    location=self.location,
                    credentials=credentials
                )
            else:
                aiplatform.init(project=self.project_id, location=self.location)
            
            # Prediction í´ë¼ì´ì–¸íŠ¸
            self.vertex_client = aiplatform.gapic.PredictionServiceClient()
            logger.info("Vertex AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
            
        except Exception as e:
            logger.error(f"í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def load_checkpoint(self) -> Optional[Dict]:
        """ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        try:
            if os.path.exists(self.checkpoint_file):
                with open(self.checkpoint_file, 'r', encoding='utf-8') as f:
                    checkpoint = json.load(f)
                logger.info(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {checkpoint}")
                return checkpoint
        except Exception as e:
            logger.warning(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    
    def save_checkpoint(self):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        try:
            with open(self.checkpoint_file, 'w', encoding='utf-8') as f:
                json.dump(self.stats, f, ensure_ascii=False, indent=2, default=str)
        except Exception as e:
            logger.error(f"ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get_total_review_count(self) -> int:
        """ì „ì²´ ë¦¬ë·° ìˆ˜ ì¡°íšŒ"""
        try:
            cursor = self.mysql_conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM reviews")
            count = cursor.fetchone()[0]
            cursor.close()
            return count
        except Exception as e:
            logger.error(f"ë¦¬ë·° ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return 0
    
    def fetch_reviews_batch(self, offset: int, limit: int) -> List[Dict[str, Any]]:
        """ë¦¬ë·° ë°°ì¹˜ ì¡°íšŒ"""
        try:
            query = """
            SELECT 
                r.review_id,
                r.product_no,
                r.member_no,
                r.rating,
                r.review_text,
                r.review_date,
                r.helpful_count,
                r.created_at,
                r.updated_at,
                p.product_name,
                p.brand as product_brand
            FROM reviews r
            LEFT JOIN products p ON r.product_no = p.product_no
            WHERE r.review_id > %s
            ORDER BY r.review_id
            LIMIT %s
            """
            
            cursor = self.mysql_conn.cursor(dictionary=True)
            cursor.execute(query, (offset, limit))
            reviews = cursor.fetchall()
            cursor.close()
            
            return reviews
            
        except Exception as e:
            logger.error(f"ë¦¬ë·° ë°°ì¹˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    async def generate_embeddings_batch(self, texts: List[str]) -> List[List[float]]:
        """í…ìŠ¤íŠ¸ ë°°ì¹˜ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        try:
            if not self.vertex_client:
                raise Exception("Vertex AI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            endpoint = f"projects/{self.project_id}/locations/{self.location}/publishers/google/models/{self.model_name}"
            embeddings = []
            
            # API ì œí•œì„ ê³ ë ¤í•œ ì‘ì€ ë°°ì¹˜ë¡œ ë¶„í• 
            for i in range(0, len(texts), self.embedding_batch_size):
                batch_texts = texts[i:i + self.embedding_batch_size]
                
                instances = []
                for text in batch_texts:
                    # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
                    cleaned_text = self.preprocess_text(text)
                    instances.append({
                        "content": cleaned_text,
                        "task_type": "RETRIEVAL_DOCUMENT"
                    })
                
                # API í˜¸ì¶œ (ìµœì‹  ë°©ì‹)
                try:
                    # ìµœì‹  Vertex AI SDK ì‚¬ìš©
                    import vertexai
                    from vertexai.language_models import TextEmbeddingModel
                    
                    # Vertex AI ì´ˆê¸°í™”
                    vertexai.init(project=self.project_id, location=self.location)
                    
                    # ëª¨ë¸ ë¡œë“œ
                    model = TextEmbeddingModel.from_pretrained(self.model_name)
                    
                    # ë°°ì¹˜ ì„ë² ë”© ìƒì„±
                    processed_texts = [self.preprocess_text(text) for text in batch_texts]
                    embeddings_response = model.get_embeddings(processed_texts)
                    
                    # ì„ë² ë”© ì¶”ì¶œ
                    for embedding_obj in embeddings_response:
                        embeddings.append(embedding_obj.values)
                    
                    # API ì œí•œì„ ìœ„í•œ ëŒ€ê¸°
                    await asyncio.sleep(0.1)
                    
                except Exception as e:
                    logger.error(f"Vertex AI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                    # ì‹¤íŒ¨í•œ ê²½ìš° ë¹ˆ ì„ë² ë”© ì¶”ê°€
                    for _ in batch_texts:
                        embeddings.append([])
            
            return embeddings
            
        except Exception as e:
            logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    def preprocess_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        if not text:
            return ""
        
        # ê¸°ë³¸ ì •ë¦¬
        cleaned = str(text).strip()
        
        # ê¸¸ì´ ì œí•œ (Vertex AI ëª¨ë¸ ì œí•œ ê³ ë ¤)
        max_length = 3000
        if len(cleaned) > max_length:
            cleaned = cleaned[:max_length] + "..."
        
        return cleaned
    
    def update_opensearch_reviews(self, reviews_with_embeddings: List[Dict[str, Any]]) -> int:
        """OpenSearchì— ì„ë² ë”© ì •ë³´ ì—…ë°ì´íŠ¸"""
        try:
            successful_updates = 0
            
            for review_data in reviews_with_embeddings:
                try:
                    review_id = review_data['review_id']
                    embedding = review_data.get('embedding', [])
                    
                    if not embedding:
                        continue
                    
                    # OpenSearch ë¬¸ì„œ ì—…ë°ì´íŠ¸ (review_idë¡œ ê²€ìƒ‰)
                    doc_body = {
                        "doc": {
                            "review_embedding": embedding,
                            "embedding_model": self.model_name,
                            "embedding_updated_at": datetime.now().isoformat()
                        }
                    }
                    
                    # review_idë¡œ ë¬¸ì„œ ê²€ìƒ‰ í›„ ì—…ë°ì´íŠ¸
                    search_query = {
                        "query": {
                            "term": {
                                "review_id": review_id
                            }
                        }
                    }
                    
                    search_response = self.opensearch_client.search(
                        index="reviews",
                        body=search_query,
                        size=1
                    )
                    
                    if search_response['hits']['total']['value'] > 0:
                        doc_id = search_response['hits']['hits'][0]['_id']
                        response = self.opensearch_client.update(
                            index="reviews",
                            id=doc_id,
                            body=doc_body,
                            retry_on_conflict=3
                        )
                    else:
                        logger.warning(f"review_id {review_id}ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        continue
                    
                    if response.get('result') in ['updated', 'noop']:
                        successful_updates += 1
                    
                except Exception as e:
                    logger.warning(f"ë¦¬ë·° {review_data.get('review_id')} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                    continue
            
            return successful_updates
            
        except Exception as e:
            logger.error(f"OpenSearch ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return 0
    
    async def process_reviews_batch(self, reviews: List[Dict[str, Any]]) -> int:
        """ë¦¬ë·° ë°°ì¹˜ ì²˜ë¦¬"""
        if not reviews:
            return 0
        
        try:
            # ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìƒí’ˆëª… + ë¦¬ë·° ë‚´ìš©)
            texts = []
            for review in reviews:
                product_name = review.get('product_name', '')
                review_text = review.get('review_text', '')
                combined_text = f"{product_name} {review_text}".strip()
                texts.append(combined_text)
            
            # ì„ë² ë”© ìƒì„±
            logger.info(f"{len(texts)}ê°œ ë¦¬ë·° ì„ë² ë”© ìƒì„± ì‹œì‘...")
            print(f"ğŸ”„ Vertex AI ì„ë² ë”© ìƒì„± ì¤‘... ({len(texts)}ê°œ í…ìŠ¤íŠ¸)")
            embeddings = await self.generate_embeddings_batch(texts)
            print(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ! ({len(embeddings)}ê°œ ìƒì„±ë¨)")
            
            # ë¦¬ë·°ì™€ ì„ë² ë”© ê²°í•©
            reviews_with_embeddings = []
            for i, review in enumerate(reviews):
                embedding = embeddings[i] if i < len(embeddings) else []
                review_data = review.copy()
                review_data['embedding'] = embedding
                reviews_with_embeddings.append(review_data)
            
            # OpenSearch ì—…ë°ì´íŠ¸
            print(f"ğŸ’¾ OpenSearchì— ì„ë² ë”© ì €ì¥ ì¤‘... ({len(reviews_with_embeddings)}ê°œ)")
            successful_updates = self.update_opensearch_reviews(reviews_with_embeddings)
            print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ! ({successful_updates}/{len(reviews_with_embeddings)}ê°œ ì„±ê³µ)")
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats['processed_reviews'] += len(reviews)
            self.stats['successful_embeddings'] += successful_updates
            self.stats['failed_embeddings'] += (len(reviews) - successful_updates)
            
            if reviews:
                self.stats['last_processed_id'] = max(review['review_id'] for review in reviews)
            
            logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {successful_updates}/{len(reviews)} ì„±ê³µ")
            return successful_updates
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return 0
    
    def print_progress(self):
        """ì§„í–‰ìƒí™© ì¶œë ¥"""
        if self.stats['total_reviews'] > 0:
            progress = (self.stats['processed_reviews'] / self.stats['total_reviews']) * 100
        else:
            progress = 0
        
        elapsed_time = time.time() - self.stats['start_time'] if self.stats['start_time'] else 0
        
        # ì§„í–‰ë¥  ë°” ìƒì„±
        bar_length = 30
        filled_length = int(bar_length * progress / 100)
        bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)
        
        print(f"\n{'='*60}")
        print(f"ğŸš€ ë¦¬ë·° ì„ë² ë”© ì§„í–‰ ìƒí™©")
        print(f"{'='*60}")
        print(f"ğŸ“Š ì „ì²´ ì§„í–‰ë¥ : [{bar}] {progress:.1f}%")
        print(f"ğŸ“ˆ í†µê³„:")
        print(f"   â€¢ ì „ì²´ ë¦¬ë·°: {self.stats['total_reviews']:,}ê°œ")
        print(f"   â€¢ ì²˜ë¦¬ ì™„ë£Œ: {self.stats['processed_reviews']:,}ê°œ")
        print(f"   â€¢ ì„±ê³µ ì„ë² ë”©: {self.stats['successful_embeddings']:,}ê°œ âœ…")
        print(f"   â€¢ ì‹¤íŒ¨ ì„ë² ë”©: {self.stats['failed_embeddings']:,}ê°œ âŒ")
        print(f"   â€¢ ë§ˆì§€ë§‰ ì²˜ë¦¬ ID: {self.stats['last_processed_id']}")
        
        if self.stats['processed_reviews'] > 0:
            avg_time = elapsed_time / self.stats['processed_reviews']
            remaining = self.stats['total_reviews'] - self.stats['processed_reviews']
            eta = remaining * avg_time
            
            # ì‹œê°„ í¬ë§·íŒ…
            elapsed_str = self._format_time(elapsed_time)
            eta_str = self._format_time(eta)
            
            print(f"â±ï¸  ì‹œê°„ ì •ë³´:")
            print(f"   â€¢ ê²½ê³¼ ì‹œê°„: {elapsed_str}")
            print(f"   â€¢ í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.2f}ì´ˆ/ê°œ")
            print(f"   â€¢ ì˜ˆìƒ ì™„ë£Œ ì‹œê°„: {eta_str} í›„")
            
            # ì²˜ë¦¬ ì†ë„ ê³„ì‚°
            if elapsed_time > 0:
                rate = self.stats['processed_reviews'] / elapsed_time
                print(f"   â€¢ ì²˜ë¦¬ ì†ë„: {rate:.1f}ê°œ/ì´ˆ")
        
        print(f"{'='*60}")
    
    def _format_time(self, seconds: float) -> str:
        """ì´ˆë¥¼ ì½ê¸° ì‰¬ìš´ ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if seconds < 60:
            return f"{seconds:.1f}ì´ˆ"
        elif seconds < 3600:
            minutes = seconds / 60
            return f"{minutes:.1f}ë¶„"
        else:
            hours = seconds / 3600
            return f"{hours:.1f}ì‹œê°„"
    
    async def run(self, resume: bool = False, max_reviews: Optional[int] = None):
        """ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì‹¤í–‰"""
        try:
            # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            logger.info("í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
            self.initialize_clients()
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            if resume:
                checkpoint = self.load_checkpoint()
                if checkpoint:
                    self.stats.update(checkpoint)
                    logger.info(f"ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘: ID {self.stats['last_processed_id']}ë¶€í„°")
            
            # ì „ì²´ ë¦¬ë·° ìˆ˜ ì¡°íšŒ
            if self.stats['total_reviews'] == 0:
                self.stats['total_reviews'] = self.get_total_review_count()
                if max_reviews:
                    self.stats['total_reviews'] = min(self.stats['total_reviews'], max_reviews)
            
            logger.info(f"ì´ {self.stats['total_reviews']:,}ê°œ ë¦¬ë·° ì²˜ë¦¬ ì‹œì‘")
            
            # ì‹œì‘ ì‹œê°„ ê¸°ë¡
            if not self.stats['start_time']:
                self.stats['start_time'] = time.time()
            
            # ë°°ì¹˜ ì²˜ë¦¬
            offset = self.stats['last_processed_id']
            processed_count = 0
            
            while processed_count < self.stats['total_reviews']:
                # ë¦¬ë·° ë°°ì¹˜ ì¡°íšŒ
                reviews = self.fetch_reviews_batch(offset, self.batch_size)
                
                if not reviews:
                    logger.info("ë” ì´ìƒ ì²˜ë¦¬í•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    break
                
                # ìµœëŒ€ ì²˜ë¦¬ ìˆ˜ ì œí•œ
                if max_reviews and self.stats['processed_reviews'] >= max_reviews:
                    logger.info(f"ìµœëŒ€ ì²˜ë¦¬ ìˆ˜ {max_reviews}ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                    break
                
                # ë°°ì¹˜ ì²˜ë¦¬
                success_count = await self.process_reviews_batch(reviews)
                
                # ì§„í–‰ìƒí™© ì¶œë ¥ (ë” ìì£¼ ì—…ë°ì´íŠ¸)
                if self.stats['processed_reviews'] % (self.batch_size * 2) == 0:
                    self.print_progress()
                    self.save_checkpoint()
                
                # ë‹¤ìŒ ë°°ì¹˜ë¥¼ ìœ„í•œ offset ì—…ë°ì´íŠ¸
                if reviews:
                    offset = max(review['review_id'] for review in reviews)
                
                processed_count += len(reviews)
                
                # API ì œí•œì„ ìœ„í•œ ëŒ€ê¸°
                await asyncio.sleep(0.5)
            
            # ìµœì¢… ê²°ê³¼
            self.print_progress()
            self.save_checkpoint()
            
            logger.info("ğŸ‰ ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì™„ë£Œ!")
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.save_checkpoint()
            raise
        
        finally:
            # ì—°ê²° ì •ë¦¬
            if self.mysql_conn:
                self.mysql_conn.close()


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ë¦¬ë·° ë°ì´í„° ë°°ì¹˜ ì„ë² ë”© ìƒì„±")
    parser.add_argument("--resume", action="store_true", help="ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘")
    parser.add_argument("--max-reviews", type=int, help="ìµœëŒ€ ì²˜ë¦¬í•  ë¦¬ë·° ìˆ˜")
    parser.add_argument("--batch-size", type=int, default=50, help="MySQL ë°°ì¹˜ ì‚¬ì´ì¦ˆ")
    parser.add_argument("--embedding-batch-size", type=int, default=5, help="Vertex AI ë°°ì¹˜ ì‚¬ì´ì¦ˆ")
    
    args = parser.parse_args()
    
    # ë°°ì¹˜ ì²˜ë¦¬ê¸° ìƒì„±
    batch_processor = ReviewEmbeddingBatch()
    
    # ì„¤ì • ì—…ë°ì´íŠ¸
    if args.batch_size:
        batch_processor.batch_size = args.batch_size
    if args.embedding_batch_size:
        batch_processor.embedding_batch_size = args.embedding_batch_size
    
    # ì‹¤í–‰
    await batch_processor.run(resume=args.resume, max_reviews=args.max_reviews)


if __name__ == "__main__":
    # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    from dotenv import load_dotenv
    load_dotenv(os.path.join(os.path.dirname(__file__), '..', '..', 'config', 'development.env'))
    
    # ì‹¤í–‰
    asyncio.run(main()) 