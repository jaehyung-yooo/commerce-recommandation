#!/usr/bin/env python3
"""
ë¦¬ë·° ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸
- í¬ë¡¤ë§ëœ ë¦¬ë·° ë°ì´í„°ë¥¼ MySQL ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë³€í™˜
- reviews.csv ìƒì„±
"""

import pandas as pd
import re
from pathlib import Path
import logging
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ReviewsMigration:
    def __init__(self):
        self.review_data = []
        self.product_mapping = {}  # product_no -> product_no (í™•ì¸ìš©)
        self.member_mapping = {}   # reviewer_id -> member_no
        
    def clean_text(self, text):
        """í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if pd.isna(text) or text is None:
            return ""
        text = str(text).strip()
        # HTML íƒœê·¸ ì œê±°
        text = re.sub(r'<[^>]+>', '', text)
        # ì—°ì† ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)
        return text.strip()
    
    def parse_date(self, date_str):
        """ë‚ ì§œ íŒŒì‹± (2025.07.20 -> 2025-07-20)"""
        if pd.isna(date_str) or not date_str:
            return None
        
        try:
            # ì ìœ¼ë¡œ êµ¬ë¶„ëœ ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬
            date_str = str(date_str).strip()
            if '.' in date_str:
                date_str = date_str.replace('.', '-')
            
            # ë‚ ì§œ ìœ íš¨ì„± ê²€ì‚¬
            datetime.strptime(date_str, '%Y-%m-%d')
            return date_str
        except:
            logger.warning(f"âš ï¸ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {date_str}")
            return None
    
    def load_product_mapping(self, products_file="../../data/mysql_ready/products.csv"):
        """ìƒí’ˆ ë§¤í•‘ ë¡œë“œ"""
        logger.info("ğŸ“¦ ìƒí’ˆ ë§¤í•‘ ë¡œë“œ")
        
        try:
            df_products = pd.read_csv(products_file)
            
            # product_id -> product_no ë§¤í•‘ ìƒì„± (í¬ë¡¤ë§ ë°ì´í„°ì˜ product_noëŠ” ì‹¤ì œë¡œëŠ” product_id)
            for _, row in df_products.iterrows():
                product_id = row['product_id']  # í¬ë¡¤ë§ ë°ì´í„°ì™€ ë§¤ì¹­ë˜ëŠ” ID
                product_no = row['product_no']  # MySQLì˜ ìˆœì°¨ ë²ˆí˜¸
                
                if pd.notna(product_id):
                    self.product_mapping[product_id] = product_no
            
            logger.info(f"âœ… ìƒí’ˆ ë§¤í•‘ ë¡œë“œ ì™„ë£Œ: {len(self.product_mapping):,}ê°œ")
            
        except Exception as e:
            logger.error(f"âŒ ìƒí’ˆ ë§¤í•‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
        
        return True
    
    def load_member_mapping(self, members_file="../../data/mysql_ready/members.csv"):
        """íšŒì› ë§¤í•‘ ë¡œë“œ"""
        logger.info("ğŸ‘¥ íšŒì› ë§¤í•‘ ë¡œë“œ")
        
        try:
            df_members = pd.read_csv(members_file)
            
            # reviewer_id(member_id) -> member_no ë§¤í•‘ ìƒì„±
            for _, row in df_members.iterrows():
                member_id = row['member_id']  # ì´ê²Œ reviewer_id
                member_no = row['member_no']
                self.member_mapping[member_id] = member_no
            
            logger.info(f"âœ… íšŒì› ë§¤í•‘ ë¡œë“œ ì™„ë£Œ: {len(self.member_mapping):,}ê°œ")
            
        except Exception as e:
            logger.error(f"âŒ íšŒì› ë§¤í•‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
        
        return True
    
    def analyze_review_data(self, df):
        """ë¦¬ë·° ë°ì´í„° ë¶„ì„"""
        logger.info("ğŸ” ë¦¬ë·° ë°ì´í„° ë¶„ì„")
        
        total_reviews = len(df)
        logger.info(f"ğŸ“Š ì´ ë¦¬ë·° ìˆ˜: {total_reviews:,}ê°œ")
        
        # ì»¬ëŸ¼ í™•ì¸
        logger.info(f"ğŸ“‹ ì»¬ëŸ¼: {list(df.columns)}")
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_cols = ['product_no', 'reviewer_id', 'rating', 'review_content', 'review_date']
        missing_cols = [col for col in required_cols if col not in df.columns]
        
        if missing_cols:
            logger.error(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")
            return False
        
        # ë°ì´í„° í’ˆì§ˆ í™•ì¸
        valid_product_no = df['product_no'].notna().sum()
        valid_reviewer_id = df['reviewer_id'].notna().sum()
        valid_rating = df['rating'].between(1, 5).sum()
        
        logger.info(f"ğŸ¯ ìœ íš¨í•œ product_no: {valid_product_no:,}ê°œ ({valid_product_no/total_reviews*100:.1f}%)")
        logger.info(f"ğŸ¯ ìœ íš¨í•œ reviewer_id: {valid_reviewer_id:,}ê°œ ({valid_reviewer_id/total_reviews*100:.1f}%)")
        logger.info(f"ğŸ¯ ìœ íš¨í•œ rating: {valid_rating:,}ê°œ ({valid_rating/total_reviews*100:.1f}%)")
        
        # í‰ì  ë¶„í¬
        rating_dist = df['rating'].value_counts().sort_index()
        logger.info("â­ í‰ì  ë¶„í¬:")
        for rating, count in rating_dist.items():
            logger.info(f"   {rating}ì : {count:,}ê°œ ({count/total_reviews*100:.1f}%)")
        
        return True
    
    def process_reviews(self, df):
        """ë¦¬ë·° ë°ì´í„° ì²˜ë¦¬"""
        logger.info("ğŸ“ ë¦¬ë·° ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
        
        processed_count = 0
        skipped_count = 0
        
        for idx, row in df.iterrows():
            try:
                # í•„ìˆ˜ ë°ì´í„° í™•ì¸
                product_no = row.get('product_no')
                reviewer_id = row.get('reviewer_id')
                rating = row.get('rating')
                
                # ìœ íš¨ì„± ê²€ì‚¬
                if pd.isna(product_no) or pd.isna(reviewer_id) or pd.isna(rating):
                    skipped_count += 1
                    continue
                
                # ìƒí’ˆ ë§¤í•‘ í™•ì¸
                if product_no not in self.product_mapping:
                    skipped_count += 1
                    continue
                
                # íšŒì› ë§¤í•‘ í™•ì¸
                if reviewer_id not in self.member_mapping:
                    skipped_count += 1
                    continue
                
                # í‰ì  ìœ íš¨ì„± í™•ì¸
                if not (1 <= rating <= 5):
                    skipped_count += 1
                    continue
                
                # ë§¤í•‘ëœ ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸°
                mapped_product_no = self.product_mapping[product_no]
                mapped_member_no = self.member_mapping[reviewer_id]
                
                # ë¦¬ë·° í…ìŠ¤íŠ¸ ì •ë¦¬
                review_text = self.clean_text(row.get('review_content', ''))
                if not review_text:
                    review_text = None  # ë¹ˆ ë¦¬ë·°ëŠ” NULLë¡œ ì²˜ë¦¬
                
                # ë¦¬ë·° ë‚ ì§œ íŒŒì‹±
                review_date = self.parse_date(row.get('review_date'))
                
                # ë¦¬ë·° ë°ì´í„° ìƒì„±
                review_data = {
                    'product_no': mapped_product_no,
                    'member_no': mapped_member_no,
                    'rating': int(rating),
                    'review_text': review_text,
                    'review_date': review_date,
                    'helpful_count': 0  # ê¸°ë³¸ê°’
                }
                
                self.review_data.append(review_data)
                processed_count += 1
                
                # ì§„í–‰ìƒí™© í‘œì‹œ
                if processed_count % 10000 == 0:
                    logger.info(f"   ì²˜ë¦¬ ì§„í–‰: {processed_count:,}ê°œ ì™„ë£Œ...")
                
            except Exception as e:
                logger.warning(f"âš ï¸ ë¦¬ë·° ì²˜ë¦¬ ì˜¤ë¥˜ (í–‰ {idx}): {e}")
                skipped_count += 1
                continue
        
        logger.info(f"âœ… ë¦¬ë·° ì²˜ë¦¬ ì™„ë£Œ: {processed_count:,}ê°œ ì²˜ë¦¬, {skipped_count:,}ê°œ ìŠ¤í‚µ")
        
        # ë§¤í•‘ ì‹¤íŒ¨ í†µê³„
        total_input = len(df)
        success_rate = (processed_count / total_input) * 100 if total_input > 0 else 0
        logger.info(f"ğŸ“Š ì²˜ë¦¬ ì„±ê³µë¥ : {success_rate:.1f}% ({processed_count}/{total_input})")
        
    def save_csv_files(self, output_dir="../../data/mysql_ready"):
        """CSV íŒŒì¼ ì €ì¥"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # Reviews CSV
        if self.review_data:
            df_reviews = pd.DataFrame(self.review_data)
            reviews_file = output_path / 'reviews.csv'
            df_reviews.to_csv(reviews_file, index=False, encoding='utf-8-sig')
            logger.info(f"âœ… {reviews_file} ì €ì¥ ì™„ë£Œ: {len(self.review_data):,}ê°œ")
        
        logger.info(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_path.resolve()}")
    
    def run(self, input_file=None):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        logger.info("ğŸš€ ë¦¬ë·° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
        
        # ì…ë ¥ íŒŒì¼ ì°¾ê¸°
        if not input_file:
            possible_files = [
                "../../crawler/reviews.csv",
                "reviews.csv"
            ]
            
            for file_path in possible_files:
                if Path(file_path).exists():
                    input_file = file_path
                    break
            
            if not input_file:
                logger.error(f"âŒ ë¦¬ë·° ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {possible_files}")
                return False
        
        # ë§¤í•‘ ë°ì´í„° ë¡œë“œ
        if not self.load_product_mapping():
            return False
        
        if not self.load_member_mapping():
            return False
        
        # ë°ì´í„° ë¡œë“œ
        logger.info(f"ğŸ“ ë°ì´í„° ë¡œë“œ: {input_file}")
        try:
            df = pd.read_csv(input_file, encoding='utf-8')
            logger.info(f"ğŸ“Š ë¡œë“œëœ ë°ì´í„°: {len(df):,}í–‰ x {len(df.columns):,}ì—´")
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
        
        # ë°ì´í„° ë¶„ì„ ë° ì²˜ë¦¬
        if not self.analyze_review_data(df):
            return False
        
        self.process_reviews(df)
        
        # CSV ì €ì¥
        self.save_csv_files()
        
        # ìš”ì•½ ì •ë³´
        logger.info("=" * 60)
        logger.info("ğŸ“‹ ë¦¬ë·° ë§ˆì´ê·¸ë ˆì´ì…˜ ìš”ì•½")
        logger.info(f"ğŸ“Š ì›ë³¸ ë¦¬ë·° ë°ì´í„°: {len(df):,}í–‰")
        logger.info(f"ğŸ“ ìƒì„±ëœ ë¦¬ë·°: {len(self.review_data):,}ê°œ")
        
        # í†µê³„ ì •ë³´
        if self.review_data:
            ratings = [review['rating'] for review in self.review_data]
            avg_rating = sum(ratings) / len(ratings)
            rating_dist = pd.Series(ratings).value_counts().sort_index()
            
            logger.info(f"â­ í‰ê·  í‰ì : {avg_rating:.2f}ì ")
            logger.info("ğŸ“Š í‰ì  ë¶„í¬:")
            for rating, count in rating_dist.items():
                logger.info(f"   {rating}ì : {count:,}ê°œ ({count/len(ratings)*100:.1f}%)")
            
            # í…ìŠ¤íŠ¸ ë¦¬ë·° ë¹„ìœ¨
            text_reviews = sum(1 for review in self.review_data if review['review_text'])
            text_rate = (text_reviews / len(self.review_data)) * 100
            logger.info(f"ğŸ“ í…ìŠ¤íŠ¸ ë¦¬ë·° ë¹„ìœ¨: {text_rate:.1f}% ({text_reviews:,}/{len(self.review_data):,})")
            
            # ë‚ ì§œ ì •ë³´
            dated_reviews = sum(1 for review in self.review_data if review['review_date'])
            date_rate = (dated_reviews / len(self.review_data)) * 100
            logger.info(f"ğŸ“… ë‚ ì§œ ì •ë³´ ë¹„ìœ¨: {date_rate:.1f}% ({dated_reviews:,}/{len(self.review_data):,})")
        
        logger.info("=" * 60)
        logger.info("ğŸ‰ ë¦¬ë·° ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        return True

def main():
    migration = ReviewsMigration()
    success = migration.run()
    return success

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 